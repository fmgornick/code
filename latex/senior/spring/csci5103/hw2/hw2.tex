\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts} 
\usepackage{amsthm}
\usepackage{caption}
\usepackage{enumitem} 
\usepackage{soul}
\usepackage{mathtools}
\usepackage{clrscode3e}
\usepackage{graphicx}
\usepackage{listings}
\usepackage{tikz}
\usetikzlibrary {arrows.meta,bending}
\usepackage[top=2cm,bottom=2cm,left=1.5cm,right=2cm,marginparwidth=1.75cm]{geometry}
\setlength{\parindent}{0cm}

\newcommand{\R}{\mathbb{R}}
\newcommand{\n}{\vspace{0.3cm}}

\def\lc{\left\lceil}   
\def\rc{\right\rceil}
\def\lf{\left\lfloor}   
\def\rf{\right\rfloor}

\newtheorem{theorem}{Theorem}

\pagenumbering{gobble}
\title{\vspace{-1.0cm}\textbf{CSCI 5103 Assignment 2}}
\date{February 10, 2023}
\author{\textbf{Fletcher Gornick}\\(x500: gorni025, ID: 5579904)}

\begin{document}
\maketitle

\begin{enumerate}
  \item Suppose that it takes 15 milliseconds of CPU to get a request for work, dispatch it, and do the rest of the necessary processing, assuming that the data needed are in the main memory.  If a disk storage server operation is needed, as is the case for \ul{one-third of the requests}, an additional 75 millisecond is required, during which time the thread sleeps.
    \begin{enumerate}
      \item How many requests per second can this server handle if it is single-threaded? \n\\
        Every \(1/3\) requests will take \(15+75=90\) ms of CPU time, and 15 ms for the other \(2/3\) times, so on average it takes \(\frac{15 + 15 + 90}{3} = 40\) ms to complete one request.  This means the single-threaded server should be able to handle \(\frac{1000}{40} = \textbf{25}\) requests per second. \n

      \item How many requests per second can this web-server handle if it is multi-threaded?  Assume that the storage server handles the requests \ul{sequentially} and for each request it takes 75 milliseconds to complete the I/O. \n\\
        In this case, whenever a thread sleeps to wait for I/O, we can simply switch to a different thread, so each request takes 15 ms.  There is still the case where the last thread scheduled will need to fully complete I/0, so we do need to account for the last 75ms of lost time. \\
        This results in \(\frac{1000 - 75}{15} = \textbf{61.67}\) requests per second.\n

      \item Now consider a system with a slightly different kind of high performance storage system.  Assume that this storage server can handle any number of requests concurrently and each I/O request completes in 75 milliseconds.  How many service requests per second can this web server handle if it is multi-threaded? \n\\
        For the last case, we can context switch the threads whenever, so with a good enough scheduler, we never need to waste CPU time waiting for I/O.  This means we should be able to handle \(\frac{1000}{15} = \textbf{66.67}\) requests per second. \n
    \end{enumerate}
    \newpage

  \item Consider a system with a single CPU server in which jobs arrive at rate \(\textbf{A}\) jobs per unit time.  Each job requires average \(\textbf{S}\) units of CPU time.  Assume that the jobs arrive at \ul{random points in time}.  Moreover, assume that jobs are processed using the \ul{FCFS scheduling policy}.  There are no I/O operations involved in processing a job.
    \begin{enumerate}
      \item What is the CPU utilization, denoted by \(\textbf{U}\) in this system?  Express \(\textbf{U}\) in terms of \(\textbf{A}\) and \(\textbf{S}\). \n\\
        period of time between each job is \(P = \frac{1}{A}\).  If it takes \(P\) units of CPU time for a job to arrive, and \(S\) units of time to complete a job, then the CPU is busy \(\frac{S}{P} = SA\) (should be between 0 and 1 unless jobs arrive too fast).  If there are more jobs then the CPU can handle it should just max out at 100\% CPU power, so \(U = \min(SA,1)\).  (From now on, we will assume \(SA \leq 1\).) \n

      \item Let the random variable \(X\) denote the number of jobs already present in the system when a new job arrives.
        \begin{enumerate}
          \item What is \(P(X=0)\)? This is the probability that a new arriving job finds the system idle. \n\\
            CPU utilization \(U = 1 - P(X=0) = 1 - SA\), so \(P(X=0) = 1 - SA\). \n

          \item What is the \(P(X>0)\)?  This is the probability that a new arriving job finds the system busy.\n\\
            CPU utilization \(U = P(\text{CPU busy}) = SA\), so \(P(X>0) = SA\). \n
        \end{enumerate}

      \item Let \(N\) denote the average number of jobs in this system and let \(T\) be the average turnaround time, i.e. the average amount of time a job spends in the system, starting from the instant when it enters the system to the point in time when it departs.  

        (\(N\) is also the average value of the random variable \(X\).  Given that jobs arrive at random points in time, a newly arriving job would find the average number of jobs in the system equal to \(N\). Also, by \textit{Little's Law}, \(N = AT\).)  

        \ul{In the case when a newly arriving job finds the system busy}, let \(\textbf{W}\) denote the average (expected) number of jobs it finds already present in the system.

        \textbf{What is the relationship between \(W\), \(N\) and \(U\)}? \n\\
        \(N\) Is the expected number of jobs in the system, and \(W\) is the expected number of jobs in the system given there's at least one.  Also note that for \(n=0\), \(P(X = n) \wedge P(X > 0) = 0\), and for \(n \geq 1\), \(P(X = n) \wedge P(X > 0) = P(X = n)\).
        \[N = AT = \sum_{n=0}^{\infty} n \cdot P(X=n) \implies W = \sum_{n=1}^{\infty} n \cdot \frac{P(X=n)}{P(X>0)}\]
        And since \(0 \cdot P(X=0) = 0\), we can simply pull the \(\displaystyle\frac{1}{P(X>0)}\) out of the left summation to get 
        \[W = \frac{1}{P(X>0)} \cdot \left( \sum_{n=1}^{\infty} n \cdot P(X=n) \right) = \frac{N}{U}.\]

      \item With \ul{FCFS job scheduling discipline}, an arriving job has to wait for the completion of all of the jobs before it in the system.  \textbf{\ul{Ignoring}} the amount of service a job in the system may have already received, and assuming that each of these jobs would still require \(S\) units of service-time, \textbf{give an expression for the average turnaround time T in terms of \(S\), \(U\) and \(N\)}. \n\\
        turnaround for job \(i, (1 \leq i \leq N)\), \(T(i) = \{\text{time for previous jobs}\} + \{\text{time for job } i\}\), giving us \[T(i) = \left( \sum_{j=1}^{i-1} S \right) + S = i \cdot S, \quad \text{so we can now express our equation for } T,\]
        \[T = \text{CPU utilization} \cdot \frac{\text{total turnaround time}}{\text{number of jobs}} = U \cdot \frac{\displaystyle\sum_{i=1}^{N} i \cdot S}{N} = \frac{US(N)(N+1)}{2N} = \frac{US(N+1)}{2}.\]

      \item Using Little's Law, which says \(N=AT\), and the results from the part (d) above, \textbf{derive an expression for \(N\) in terms of the server utilization \(U\)}.
        \[N=AT \iff N = \frac{UAS(N+1)}{2} \iff N = \frac{U^2(N+1)}{2} \iff N = \frac{U^2}{2-U^2}\]
    \end{enumerate}

  \item Consider a real-time system consisting of two periodic tasks.  Assume these tasks only require the CPU and do not perform any I/O.  Task A has a period of 50 seconds and requires 25 seconds of CPU time.  Task B has a period of 70 seconds and requires 28 seconds of CPU time.
    \begin{enumerate}
      \item Is the condition for \ul{Rate Monotonic} (RM) scheduling satisfied? \n
        \[\frac{25}{50} + \frac{28}{70} = 0.9 > 0.828 = 2(2^{1/2} - 1),\] 
        so \textbf{the condition for Rate Monotonic scheduling is NOT satisfied.} \n

      \item Is a schedule possible using RM-based static priorities? If yes, \ul{show a schedule}.  Otherwise, \ul{show a case} where any of these two tasks misses its deadline. \n
        \begin{center}
          \begin{tikzpicture}
            \filldraw[color=black, fill=green] (0,0) rectangle (2.5,1);
            \filldraw[color=black, fill=yellow] (2.5,0) rectangle (5,1);
            \draw[color=black, fill=green] (5,0) rectangle (7,1);
            \draw[color=black, fill=green] (7,0) rectangle (7.5,1);
            \draw[color=black, fill=yellow] (7.5,0) rectangle (7.8,1);
            \draw[color=black, fill=yellow] (7.8,0) rectangle (10,1);

            \filldraw[black] (0,0) circle (0pt) node[anchor=north]{\small 0};
            \filldraw[black] (2.5,0) circle (0pt) node[anchor=north]{\small 25};
            \filldraw[black] (5,0) circle (0pt) node[anchor=north]{\small 50};
            \filldraw[black] (7,0) circle (0pt) node[anchor=north]{\tiny 70};
            \filldraw[black] (7.5,0) circle (0pt) node[anchor=north]{\tiny 75};
            \filldraw[black] (7.8,0) circle (0pt) node[anchor=north]{\tiny 78};
            \filldraw[black] (10,0) circle (0pt) node[anchor=north]{\small 100};

            \filldraw[black] (0.9,0.5) circle (0pt) node[anchor=west]{\small \(A_0\)};
            \filldraw[black] (3.4,0.5) circle (0pt) node[anchor=west]{\small \(B_0\)};
            \filldraw[black] (5.6,0.5) circle (0pt) node[anchor=west]{\small \(A_1\)};
            \filldraw[black] (6.95,0.5) circle (0pt) node[anchor=west]{\tiny \(A_1\)};
            \filldraw[black] (7.35,0.5) circle (0pt) node[anchor=west]{\tiny \(B_0\)};
            \filldraw[black] (8.4,0.5) circle (0pt) node[anchor=west]{\small \(B_1\)};

            \draw [red] (8,1.5) [->] to [bend right] (7,1);
            \filldraw[black] (8,1.5) circle (0pt) node[anchor=west]{missed deadline for \(B_0\)};
          \end{tikzpicture}
        \end{center}

      \item Suppose we upgrade the CPU to be 25\% more powerful than the original, i.e., the power of the new CPU is 1.25 times that of the original.  Is the RM scheduling condition satisfied with this new configuration?  Keep in mind that that this does not change the task recurrence periods. \n
        Since the CPU is 25\% more powerful, so the CPU time for task \(A\) is now \(25/1.25 = 20\), and for task \(B\), it's now \(28/1.25 = 22.4\).  So we can check these new values for our RMS constraint:
        \[\frac{20}{50} + \frac{22.4}{70} = 0.72 < 0.828 = 2(2^{1/2} - 1),\] 
        so \textbf{the condition for Rate Monotonic scheduling IS satisfied.} \n

      \item Answer question (b) above with the configuration given in (c). \n
        \begin{center}
          \begin{tikzpicture}
            \filldraw[color=black, fill=green] (0,0) rectangle (2,1);
            \filldraw[color=black, fill=yellow] (2,0) rectangle (4.24,1);
            \draw (4.24,0) rectangle (5,1);
            \filldraw[color=black, fill=green] (5,0) rectangle (7,1);
            \filldraw[color=black, fill=yellow] (7,0) rectangle (9.24,1);
            \draw (9.24,0) rectangle (10,1);

            \filldraw[black] (0,0) circle (0pt) node[anchor=north]{\small 0};
            \filldraw[black] (2,0) circle (0pt) node[anchor=north]{\small 20};
            \filldraw[black] (4.24,0) circle (0pt) node[anchor=north]{\small 42.4};
            \filldraw[black] (5,0) circle (0pt) node[anchor=north]{\small 50};
            \filldraw[black] (7,0) circle (0pt) node[anchor=north]{\small 70};
            \filldraw[black] (9.24,0) circle (0pt) node[anchor=north]{\small 92.4};
            \filldraw[black] (10,0) circle (0pt) node[anchor=north]{\small 100};

            \filldraw[black] (0.7,0.5) circle (0pt) node[anchor=west]{\small \(A_0\)};
            \filldraw[black] (2.8,0.5) circle (0pt) node[anchor=west]{\small \(B_0\)};
            \filldraw[black] (5.7,0.5) circle (0pt) node[anchor=west]{\small \(A_1\)};
            \filldraw[black] (7.8,0.5) circle (0pt) node[anchor=west]{\small \(B_1\)};
          \end{tikzpicture}
        \end{center}
    \end{enumerate}
    \newpage

  \item The following solution to the \ul{two-process critical section problem} was presented in 1966, and later this solution was found to be incorrect.  \textbf{Give an example to show how the mutual exclusion requirement is violated}.

    (You \textbf{\ul{MUST show}} an interleaved execution of the steps of these two processes, leading to the violation of the mutual exclusion requirement.  Indicate line numbers for steps when showing an interleaved execution of the two processes violating the mutual exclusion requirement.) \n

    The two processes are numbered 0 and 1. \\
    The shared variables are: \\
    \hspace*{1cm} var flag: array[0..1] of boolean /* initially false */ \\
    \hspace*{1cm} turn: 0..1; /* assume any initial value */

    \begin{codebox}
     \Procname{\(\proc{Process (i)}\)}
     \zi /* i can either 0 or 1, j is (i+1) mod 2 */
     \li repeat \Do
        \zi // ENTRY PROTOCOL
        \li flag[i] = true;
        \li \While (turn != i) do \{\Do
          \li \While (flag[j]) do /* nothing */;
          \li turn = i;
        \End
        \li \}
        \li CRITICAL SECTION
        \zi // EXIT PROTOCOL
        \li flag[i] = false;
        \li \(\hdots\)
     \End
     \li until false;
    \end{codebox}
    Suppose turn = 1, and we're starting in process 0:

    \begin{tabular}{|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|c|}
      \hline
      \(P_0\) & 1 & 2 & 3 &   &   &   &   &   &   &    &   & 4 &   &   &   & 5 & 6 & 3 & 7 \\
      \hline
      \(P_1\) &   &   &   & 1 & 2 & 3 & 7 & 8 & 9 & 10 & 1 &   & 2 & 3 & 7 &   &   &   &   \\
      \hline
    \end{tabular}

    This results in both processes in the critcal section, breaking mutual exclusion. \n

    \begin{enumerate}[label=\arabic*)]
      \item Process 0 starts first, sets it's flag to true, and enters the while loop on line 3 because it's not Process 0's turn. \n

      \item Context switches and Process 1 does the same, this time it skips the while loop because it's Process 1's turn, then executes the critical section, sets it's flag to false, and loops back. \n

      \item Context switches and Process 0 sees that flag[1] is set to false so it skips the while loop on line 4. \n

      \item Context switches and Process 1 sets it's flag to true and again skips it's while loop because it's still process 1's turn, now Process 1 is in the critical section. \n

      \item Context switches, Process 0 sets the turn value to 0, then loops back.  Process 0 can now skip the while loop because turn=0, so Process 0 now enters the critical section. \n

      \item Now both processes are in the critical section and mutual exclusion is broken.
    \end{enumerate}
    \newpage

  \item \textit{\ul{Definition (Counting Semaphore)}}: A semaphore that can have any arbitrary positive integer value, including value 0.  A signal operation increases the value by 1 if there is no waiting process.

    \textit{\ul{Definition (Binary semaphore)}}: A semaphore that can have values only 0 or 1; a signal operation has no effect if the value is already 1. \n

    You are asked to \ul{show how to implement a \textit{counting semaphore} using \textit{binary semaphores}}.  In your implementation, in addition to using binary semaphores, you may use additional data items such as integer counters or Boolean flags.

    You have to show implementations of \ul{wait} and \ul{signal} operations of the counting semaphore.

    \textit{(Hint: You can use a binary semaphore with initial value 1 to implement a critical section.  For maintaining a queue of blocked processes, you can use a binary semaphore with initial value 0.)}


      \begin{codebox}
       \Procname{\(\proc{Variables}\)}
        \zi int count = N; // to keep track of the number of processes left to allow in CRITICAL SECTION
        \zi binary semaphore count\_mutex = 1; // for changing count value
        \zi binary semaphore critical\_mutex = 0; // when count = 0, wait for signal on this semaphore
      \end{codebox}

      (NOTE: when \textit{wait} and \textit{signal} are called inside the functions defined below, I'm referring to the binary semaphore version of these functions, I'm not making a recursive call.)

    \begin{minipage}{0.45\textwidth}
      \begin{codebox}
       \Procname{\(\proc{wait()}\)}
       \li wait(count\_mutex)
       \li count = count - 1
       \zi
       \li \If count \(< 0\) \Do
         \li signal(count\_mutex)
         \li wait(critical\_mutex)
       \zi
       \End
       \li
       \Else \Do
        \li signal(count\_mutex)
       \End
      \end{codebox}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
      \centering
      \begin{codebox}
       \Procname{\(\proc{signal()}\)}
       \li wait(count\_mutex)
       \li count = count + 1
       \zi
       \li \If count \(== 0\) \Do
         \li signal(critical\_mutex)
       \End
       \zi
       \li signal(count\_mutex)
      \end{codebox}
    \end{minipage} \n

    In the above code for wait, we first want to grab the lock to change count, then decrement it's value.  If our new count is less than 0, then we need to wait for another process to signal us to proceed.  Before doing this however, we must first signal the release of our count lock, otherwise we'll get an immediate deadlock.  Once we recieve the signal we're free to enter the critical section.  If however, count is greater than or equal to 0, then we're good to go anyways and we can just release the count lock and go into the critical section. \n

    For the signal function, we must first wait for access to change our count variable then increment.  Now if our count is at 0, then prior to us changing count, it was less than 0, so we must signal that another process is now free to enter the critical section.  Regardless of whether or not we signal, we still release the count lock and exit the signal function.
    \newpage

  \item \textit{Barrier synchronization problem}: A parallel program contains \(N\) processes, which execute in synchronized phases (steps).  After completing the execution of phase i, each process waits for all the other processes to complete their i’th phase. For this purpose, after executing the code for phase i, each process executes a function called \textit{BarrierSynch(i)}.  When the last process reaches the barrier and executes this synchronization function, it unblocks all the other (\(N-1\)) waiting processes to resume their execution for phase (i+1). This form of execution of steps and barrier synchronization repeats at each phase.

    Write synchronization code for the function \textit{BarrierSynch(phase-number)} using \textbf{\ul{semaphores}} and any other shared variables to implement the barrier synchronization problem described above.  (\ul{Important}: You should pay attention to \ul{race conditions} where a process resumed from i’th phase barrier may quickly finish its execution of the next phase and start executing the barrier synchronization code of function for the (i+1)’th phase while some other processes are still executing the barrier synchronization code for phase i.)

    \begin{center}
      \includegraphics[width=0.5\textwidth]{barrier-sync.png}
    \end{center}

    \begin{minipage}{0.45\textwidth}
      \begin{codebox}
       \Procname{\(\proc{Variables}\)}
        \li int count = \(N\); 
        \zi /* to keep track of the number of 
        \zi \(\;\;\;\;\) processes left to wait for in our 
        \zi \(\;\;\;\;\) barrier */
        \zi
        \li binary semaphore count\_mutex = 1; 
        \zi /* for changing count value */
        \zi
        \li binary semaphore barrier = 0; 
        \zi /* when count \(< N\), wait for signal 
        \zi \(\;\;\;\;\) to proceed to next phase */
      \end{codebox}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
      \begin{codebox}
       \Procname{\(\proc{BarrierSynch(i)}\)}
       \li wait(count\_mutex)
       \li count = count + 1
       \zi
       \li \If count \(== N\) \Do
         \li \For \(j\) in \([0..N-1]\) \Do
           \li signal(barrier)
         \End
         \li count = 0
         \li signal(count\_mutex)
       \End
       \zi
       \li
       \Else \Do
        \li signal(count\_mutex)
        \li wait(barrier)
       \End
      \end{codebox}
    \end{minipage} \n

    This implementation for \textit{BarrierSynch} avoids the potential race condition outlined above because when our count \(=N\), we signal all other processes to wake up and proceed to the next phase, but we're still holding onto the count\_mutex semaphore.  So suppose process \(j\) gets released and finishes the next phase entering the next \textit{BarrierSynch}, it won't wait for the barrier semaphore until it gets access to the count\_mutex semaphore, so it can't even wait for the barrier signal until all other processes finishes executing their barrier synchronization and enters the next phase.
    \newpage
    
  \item Suppose a system has \ul{two producer processes} \(P_1\) and \(P_2\), and one consumer process \(C_1\).  All these three processes execute concurrently, and possibly at different speeds.  This system contains a shared buffer of length \(2N\) slots for communicating items between the producers and the consumer.  An item consists of two parts, \(I_1\) and \(I_2\) which are produced by \(P_1\) and \(P_2\) respectively, i.e. \(P_1\) produces parts of type \(I_1\), and \(P_2\) produces parts of type \(I_2\).  Each part occupies one slot in the buffer, allowing for \(N\) items to exist in the buffer.  The two types of parts must occupy alternating positions in the buffer, and always appear in the same order such as \(I_1\) followed by \(I_2\).  \ul{The consumer always removes a complete item}, i.e. one part of type \(I_1\) and the other of type \(I_2\), from the buffer.

    \ul{Using semaphores, write pseudo-code of these three processes to synchronize the producers and consumer in this system}.

    Figure below shows \textbf{\ul{an example}} of possible contents of a buffer of length 8.

    \begin{center}
      \scalebox{2}{
        \begin{tabular}[c]{|l|l|l|l|l|l|l|l|}
          \hline
          \(I_1\) & \(I_2\) & \(I_1\) & \(I_2\) & \(I_1\) & \(\;\;\) & \(I_1\) & \(\;\;\) \\
          \hline
        \end{tabular}
      }
    \end{center} \n

    \begin{codebox}
     \Procname{\(\proc{Variables}\)}
      \li itemType buffer[2\(N\)]; // buffer containing our items (\(N\) items with 2 parts)
      \li int items[0..1]; // keep track of the number of items each producer process deposited
      \li int head = 0; // buffer wraps around, items array tracks tail
      \li binary semaphore mutex = 1; // for accessing shared buffer, head, tail, and items
      \li counting semaphore spaceAvailable = 2\(N\); // keep track of spaces available in our buffer
      \li counting semaphore itemAvailable = 0; // keep track of items available in our buffer
    \end{codebox}

    \begin{minipage}{0.45\textwidth}
      // procNum 0 or 1 for simplicity (not 1 or 2)
      \begin{codebox}
        \Procname{\(\proc{Deposit(int procNum, itemType item)}\)}
          \li wait(spaceAvailable)
          \li wait(mutex)
          \zi
          \zi /* process i already filled \(N\) items */
          \li \If items[i] \(== N\) \Do
            \li signal(spaceAvailable)
            \li signal(mutex)
            \li \Return
          \End
          \zi
          \zi /* add item to it's open slot */
          \li slot = \(\left(2 \cdot (\text{head + items[\(i\)]}) + i \right) \;\%\; N\)
          \li buffer[slot] = item
          \li items[i]++
          \zi
          \zi /* item available when \(I_1\) and \(I_2\) in */
          \li \If items[i] \(\leq\) items[(\(i+1\)) \% 2] \Do
            \li signal(itemAvailable) \End 
          \zi
          \End
          \li signal(mutex)
      \end{codebox}
    \end{minipage}
    \begin{minipage}{0.45\textwidth}
      \begin{codebox}
      \Procname{\(\proc{Remove(itemType *item)}\)}
      \li wait(itemAvailable)
      \li wait(mutex)
      \zi
      \zi /* grab both parts of item from head */
      \li item[0] = buffer[2 \(\cdot\) head]
      \li item[1] = buffer[2 \(\cdot\) head + 1]
      \zi
      \zi /* update location where producers add */
      \li items[0]\(--\)
      \li items[1]\(--\)
      \zi
      \li head = (head + 1) \% \(N\)
      \zi
      \zi /* signal twice to free slot for each 
      \zi \(\;\;\;\;\) producer process */
      \li signal(spaceAvailable)
      \li signal(spaceAvailable)
      \zi
      \li signal(mutex)
      \end{codebox}
    \end{minipage} \n
    \newpage

  \item Write a \ul{monitor} called \textit{Aggregator} with one interface procedure named \textit{Add(integer n)}, which will be used by three asynchronous processes as described below.

    Each process will have some integer number \(n\), which it will report to the \textit{Aggregator} by calling its interface procedure \textit{Add(n)}.  This monitor method will return the sum of the three integer values reported by these three processes after all have reported their values.

    When a process calls \textit{Add(n)} and if the other two processes haven’t yet reported their values, the execution of this procedure will get suspended.  This execution will resume when all three values have been reported and the sum of these values can be returned as the return value of \textit{Add(n)}. \n\n

\lstinputlisting[language=C++]{problem_8.c}
    
\end{enumerate}
\end{document}
