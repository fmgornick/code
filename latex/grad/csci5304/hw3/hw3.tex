\documentclass[11pt]{article}

\usepackage{amsmath}
\usepackage{amsfonts}
\usepackage{amsthm}
\usepackage{blkarray}
\usepackage{caption}
\usepackage{enumitem}
\usepackage{graphicx}
\usepackage{hyperref}
\usepackage{mathtools}
\usepackage{subfigure}
\usepackage{tikz}
\usepackage[top=1.5cm,bottom=2cm,left=1.25cm,right=1.75cm,marginparwidth=1.75cm]{geometry}
\setlength{\parindent}{0cm}

\newcommand{\R}{\mathbb{R}}
\newcommand{\n}{\vspace{0.3cm}}
\newtheorem{theorem}{Theorem}

\def\lc{\left\lceil}
\def\rc{\right\rceil}
\def\lf{\left\lfloor}
\def\rf{\right\rfloor}

\title{\vspace{-1.0cm}CSCI 5304 Homework 3}
\author{Fletcher Gornick}
\date{October 15}

\begin{document}
\maketitle
\begin{enumerate}
	\item Write a julia script that computes the LU factorization (without pivoting) of a matrix.  Test your algorithm on the matrix
	      \[A = \left(\begin{array}{rrr} 2 & 3 & -1 \\ -4 & -5 & 0 \\ -2 & -4 & 6 \\ \end{array}\right).\]
	      \begin{verbatim}
     using LinearAlgebra                      |      julia> L,U = gauss_lu(A)
                                              |      
     function gauss_lu(A)                     |      julia> L
       n, _ = size(A)                         |      3×3 Matrix{Float64}:
       L = Matrix{Float64}(I,n,n)             |        1.0   0.0  0.0
       U = float.(A)                          |       -2.0   1.0  0.0
                                              |       -1.0  -1.0  1.0
       for k=1:n-1                            |      
         for i=k+1:n                          |      julia> U
           piv = U[i,k] / U[k,k]              |      3×3 Matrix{Float64}:
           for j=k:n                          |       2.0  3.0  -1.0
             U[i,j] = U[i,j] - piv * U[k,j]   |       0.0  1.0  -2.0
           end                                |       0.0  0.0   3.0
           L[i,k] = piv                       |      
         end                                  |      julia> L * U
       end                                    |      3×3 Matrix{Float64}:
                                              |        2.0   3.0  -1.0
       L, U                                   |       -4.0  -5.0   0.0
     end                                      |       -2.0  -4.0   6.0
        \end{verbatim}

	\item Assume the IEEE standard for floating point arithmetic.  If you use the matlab command \verb!'num2hex'!, you will find that the IEEE hex representation of \(-6.0\) is
	      \[\verb!c018 0000 0000 0000!\]
	      The exponent + sign part is \verb!c01!, and the matissa is \(8\) followed by 12 zeros.  Explain why you obtain this representation.  What is the internal representation of \(-6\) in single precision?
	      \[b(x) = \overbrace{\underset{b_{63}}1}^{\text{sign}} \;\; \overbrace{\underset{b_{62}}1 00 \;\; 0000 \;\; 000 \underset{b_{52}}1}^{\text{exponent}} \;\; \overbrace{\underset{b_{51}}1 000 \;\; 0000 \;\;\hdots \;\; 000 \underset{b_0}0}^{\text{mantissa}}\]
	      Since the sign bit is set, we know \(x\) must be negative. \n

	      Let \(e\) be the number represented by \(10000000001\) in binary, so \(e = 2^{10} + 2^0 = 1025\).  Now we know that the exponential portion of \(x\) is \(2^{e-1023} = 2^2 = 4\).  So \(x = (-1) \cdot 4 \cdot m\), where \(m\) is yet to be calculated. \n

	      Finally, \(m\) can be calculated by summing up all the set bits in the matissa multiplied by their weights, and this is how we get the above hex representation for -6:
	      \[m = 1 + \sum_{i=0}^{51} b_i \times 2^{-52+i} = 1 + 1 \times 2^{-1} = 1.5 \implies x = (-1) \cdot 4 \cdot 1.5 = -6.\]

	      If instead we were to do single precision, our exponent would only be 8 bits long, and our mantissa only 23 bits long.
	      \begin{itemize}
		      \item \(b_{31} = 1\) because \(-6\) is signed.
		      \item \(2^2 = 2^{129-127}\), so \(e = 129 = 128 = 2^7 + 2^0\), meaning our exponent bits should look like \(1000\;0001\).
		      \item we still only want the most significant bit set for our mantissa in order to get 1.5, so \(b_{22} = 1\), while the rest are 0.
	      \end{itemize}
	      \[\verb!c0c0 0000! \;=\; 1100\;0000\;1100\;0000\;0000\;0000\;0000\;0000 \;=\; -6.\]

	\item In this exercise we assume the IEEE standard for floating point arithmetic in double precision.  With respect to the earlier representation \(\beta = 2, t = 53\).
	      \begin{enumerate}
		      \item What is the largest valid floating point number represented by this system? \n\\
		            To get this number, we wan't all the mantissa bits set as well as all the exponent bits.  The only bit that shouldn't be set is the sign bit.  But in the IEEE floating point standard, a value of \verb!7ff! for the exponent bits represent \(\pm \infty\), so we actually need 1 less than that to get the largest possible float.
		            \[\verb!7fef ffff ffff ffff! = 2^{2047-1023} \cdot (2^0 + 2^{-1} + \dots + 2^{-52}) \approx 2^{1024} \approx 1.797693134 \times 10^{308}.\]

		      \item What is the smallest valid positive floating point number? \n\\
		            This time, we want none of the exponent or mantiassa bits set to get the smallest positive double.  But again, IEEE assigns meaning to exponent bits \verb!000!, so we must instead use \verb!001!:
		            \[\verb!0010 0000 0000 0000! = 2^{1-1023} \cdot 2^0 \approx 2.2250738585072 \times 10^{-308}.\]

		      \item Not all positive integers are representaed exactly in this floating point system.  What is the smallesst (positive) integer that is not exactly represented?
		            \begin{align*}
			            1 & = 2^0 = 2^0 \cdot 2^0           & = \mathtt{3ff0\;0000\;0000\;0000} \\
			            2 & = 2^0 = 2^1 \cdot 2^0           & = \mathtt{4000\;0000\;0000\;0000} \\
			            3 & = 2 + 1 = 2^1 (2^0 + 2^{-1})    & = \mathtt{4008\;0000\;0000\;0000} \\
			            4 & = 2^2 = 2^2 \cdot 2^0           & = \mathtt{4010\;0000\;0000\;0000} \\
			            5 & = 2^2 + 1 =  2^2 (2^0 + 2^{-2}) & = \mathtt{4012\;0000\;0000\;0000} \\
			            \vdots
		            \end{align*}
		            It's clear that once we get to numbers larger than \(2^{53}\), we can no longer go up in increments of 1 exactly.
		            \begin{align*}
			            2^{53}   & = 2^{53} \cdot 2^0       & = \mathtt{4340\;0000\;0000\;0000} \\
			            2^{53}+1 & = 2^{53} (2^0 + 2^{-53}) & = \mathtt{?}
		            \end{align*}
		            But since our mantissa can only go down to \(2^{-52}\), we see that \(2^{53}+1\) cannot be exactly represented.
	      \end{enumerate}

	\item Consider the linear system \(Ax = b\), where \(|\varepsilon| < 4\) and:
	      \[
		      A = \left(\begin{array}{cc} 1 & 2 \\ 2 & 4-\varepsilon \\ \end{array}\right), \quad
		      b = \left(\begin{array}{c} 3 \\ 6-\varepsilon \end{array}\right).
	      \]
	      \begin{enumerate}
		      \item Solve the above linear system by Gaussian elimination with partial pivoting.
		            \[
			            \left(\begin{array}{rr|r}
					            1 & 2             & 3             \\
					            2 & 4-\varepsilon & 6-\varepsilon \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|r}
					            2 & 4-\varepsilon & 6-\varepsilon \\
					            1 & 2             & 3             \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|r}
					            2 & 4-\varepsilon      & 6-\varepsilon      \\
					            0 & \tfrac\varepsilon2 & \tfrac\varepsilon2 \\
				            \end{array}\right)
			            \implies
			            \begin{array}{c}
				            x_1 = 1 \\
				            x_2 = 1 \\
			            \end{array}
		            \]
		            The last part follows from simple back-substitution, so \(x = (1,1)^T\) \n

		      \item Now replace the \(6-\varepsilon\) in the right-hand side by 6 and solve the new system.  How does the result depend on \(\varepsilon\)?
		            \[
			            \left(\begin{array}{rr|r}
					            1 & 2             & 3 \\
					            2 & 4-\varepsilon & 6 \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|r}
					            2 & 4-\varepsilon & 6 \\
					            1 & 2             & 3 \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|r}
					            2 & 4-\varepsilon      & 6 \\
					            0 & \tfrac\varepsilon2 & 0 \\
				            \end{array}\right)
			            \implies
			            \begin{array}{c}
				            x_1 = 3 \\
				            x_2 = 0 \\
			            \end{array}
		            \]
		            Again, using back-substitution, we get \(x = (3,0)^T\).  So it look like \(x\) doesn't depend on \(\varepsilon\) at all. \n

		      \item Verify (a) and (b) with the system you obtain when \(\varepsilon = 0.001\).
		            \begin{align*}
			                     & \left(\begin{array}{cc}
					                             1 & 2       \\
					                             2 & 4-0.001 \\
				                             \end{array}\right)
			            \binom11 &
			            =        & \binom{1+2}{2+4-0.001}  &
			            =        & \binom{3}{6-0.001}      & \\
			                     & \left(\begin{array}{cc}
					                             1 & 2       \\
					                             2 & 4-0.001 \\
				                             \end{array}\right)
			            \binom30 &
			            =        & \binom{3}{3 \cdot 2}    &
			            =        & \binom{3}{6}            &
		            \end{align*}
		      \item What is the inverse of \(A\)?  What is the 1-norm condition number (assume \(\varepsilon < 3\))?  Can you explain what you observe based on your answer?
		            \[
			            \left(\begin{array}{rr|rr}
					            1 & 2             & 1 & 0 \\
					            2 & 4-\varepsilon & 0 & 1 \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|rr}
					            1 & 2            & 1  & 0 \\
					            0 & -\varepsilon & -2 & 1 \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|rr}
					            1 & 2 & 1                  & 0                   \\
					            0 & 1 & \tfrac2\varepsilon & -\tfrac1\varepsilon \\
				            \end{array}\right)
			            \to
			            \left(\begin{array}{rr|rr}
					            1 & 0 & 1 - 4/\varepsilon & 2/\varepsilon  \\
					            0 & 1 & 2/\varepsilon     & -1/\varepsilon \\
				            \end{array}\right)
		            \]
		            This gives us the following matrix for \(A^{-1}\),
		            \[
			            A^{-1} \;=\;
			            \left(\begin{array}{rr}
					            1 - 4/\varepsilon & 2/\varepsilon  \\
					            2/\varepsilon     & -1/\varepsilon \\
				            \end{array}\right)
			            \;=\;
			            \frac1\varepsilon
			            \left(\begin{array}{rr}
					            \varepsilon - 4 & 2  \\
					            2               & -1 \\
				            \end{array}\right)
		            \]
		            Since the columns of \(A\) and \(\varepsilon A^{-1}\) both have the same sums (when taking the modulus), we know condition number \(\kappa(A) = \lVert A \rVert_1 \lVert A^{-1} \rVert_1 = \frac1\varepsilon \lVert A \rVert_1^2\). \n\\
		            We know \(\varepsilon < 3\), so \(a_{:,2}\) must be the maximal column.  This gives us the following equation for \(\kappa\),
		            \[\kappa(A) = \frac1\varepsilon \lVert A \rVert_1^2 = \frac1\varepsilon\left( |2| + |4 - \varepsilon| \right)^2 = \frac1\varepsilon(6-\varepsilon)^2 = \frac{36}\varepsilon - 12 + \varepsilon.\]
		            It's clear from the above equation that, assuming \(\varepsilon > 0\), the condition number will blow up as \(\varepsilon\) approaches zero, so this matrix is very ill-conditioned for small values of \(\varepsilon\). \n
	      \end{enumerate}

	\item Consider the system
	      \[
		      Ax \equiv \left(\begin{array}{rr} -0.001 & 1.001 \\ 0.001 & -0.001 \\ \end{array}\right)
		      \binom{x_1}{x_2} = \binom10 \equiv b
	      \]
	      whose solution is \(x_1 = x_2 = 1\), and the system
	      \[(A + \Delta A)y = b + \Delta b\]
	      where \(\Delta A = \varepsilon|A|, \; \Delta b = \varepsilon|b|\).  In the following, we let \(\varepsilon = 10^{-4}\). \n\\
	      Compute \(\kappa_\infty(A)\).  Compute the actual value of \(\lVert x-y \rVert_\infty / \lVert x \rVert_\infty\) and it's estimate obtained from using the (standard) condition number \(\kappa_\infty\).

	\item \begin{enumerate}
		      \item Apply the julia script you developed in question 1 to obtain the LU factorization of the following \(n \times n\) matrix:
		            \[A = \left(\begin{array}{rrrrrrr}
					            1      & 0      & 0      & \hdots & 0      & 0      & 1      \\
					            -1     & 1      & 0      & \hdots & 0      & 0      & 1      \\
					            -1     & -1     & 1      & \hdots & 0      & 0      & 1      \\
					            \vdots & \vdots & \vdots & \ddots & \vdots & \vdots & \vdots \\
					            -1     & -1     & -1     & \hdots & 1      & 0      & 1      \\
					            -1     & -1     & -1     & \hdots & -1     & 1      & 1      \\
					            -1     & -1     & -1     & \hdots & -1     & -1     & 1      \\
				            \end{array}\right)\]
		      \item What can you say about \(\lVert U \rVert_\infty\) as a function of the size \(n\)?  How do you relate this result to question 2 of homework 2?
		      \item Compute, for the case \(n=8\), the matrix \(128 * A^{-1}\) (in julia).  Can you tell what the inverse of \(A\) is in general (for any \(n\))?  Prove your result.  What is (exactly) the 1-norm condition number of \(A\) as a function of \(n\)?  Any comments?
	      \end{enumerate}

\end{enumerate}

\end{document}
